{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60012243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 11310 to 13426\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   step            500 non-null    int64  \n",
      " 1   type            500 non-null    object \n",
      " 2   amount          500 non-null    float64\n",
      " 3   nameOrig        500 non-null    object \n",
      " 4   oldbalanceOrg   500 non-null    float64\n",
      " 5   newbalanceOrig  500 non-null    float64\n",
      " 6   nameDest        500 non-null    object \n",
      " 7   oldbalanceDest  500 non-null    float64\n",
      " 8   newbalanceDest  500 non-null    float64\n",
      " 9   isFraud         500 non-null    int64  \n",
      " 10  isFlaggedFraud  500 non-null    int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 46.9+ KB\n",
      "None\n",
      "step              0\n",
      "type              0\n",
      "amount            0\n",
      "nameOrig          0\n",
      "oldbalanceOrg     0\n",
      "newbalanceOrig    0\n",
      "nameDest          0\n",
      "oldbalanceDest    0\n",
      "newbalanceDest    0\n",
      "isFraud           0\n",
      "isFlaggedFraud    0\n",
      "dtype: int64\n",
      "Training data shape: (400, 10)\n",
      "Testing data shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. Import Libraries\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# =========================\n",
    "# 2. Load Dataset\n",
    "# =========================\n",
    "df = pd.read_csv(\"balanced_fraud_dataset.csv\")\n",
    "df=df.sample(500)\n",
    "df.to_csv(\"data.csv\",index=False)\n",
    "\n",
    "# =========================\n",
    "# 3. Basic Inspection\n",
    "# =========================\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# =========================\n",
    "# 4. Drop Unnecessary Columns\n",
    "# (IDs that don't help model)\n",
    "# =========================\n",
    "df = df.drop([\"nameOrig\", \"nameDest\"], axis=1)\n",
    "\n",
    "# =========================\n",
    "# 5. Feature Engineering\n",
    "# =========================\n",
    "# Balance difference features\n",
    "df[\"orgBalanceDiff\"] = df[\"oldbalanceOrg\"] - df[\"newbalanceOrig\"]\n",
    "df[\"destBalanceDiff\"] = df[\"newbalanceDest\"] - df[\"oldbalanceDest\"]\n",
    "\n",
    "# =========================\n",
    "# 6. Encode Categorical Feature\n",
    "# =========================\n",
    "le = LabelEncoder()\n",
    "df[\"type\"] = le.fit_transform(df[\"type\"])\n",
    "\n",
    "# =========================\n",
    "# 7. Define Features and Target\n",
    "# =========================\n",
    "X = df.drop(\"isFraud\", axis=1)\n",
    "y = df[\"isFraud\"]\n",
    "\n",
    "# =========================\n",
    "# 8. Train-Test Split\n",
    "# =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 9. Feature Scaling\n",
    "# =========================\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Training data shape:\", X_train_scaled.shape)\n",
    "print(\"Testing data shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7247f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ArchitSaki/Fraud-Detection-System--End-to-end-ml-project- initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository ArchitSaki/Fraud-Detection-System--End-to-end-ml-project- initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# df=pd.read_csv(\"data.csv\")\n",
    "\n",
    "\n",
    "# import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow')\n",
    "dagshub.init(repo_owner='ArchitSaki', repo_name='Fraud-Detection-System--End-to-end-ml-project-', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b0e12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb28470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/24 16:03:54 INFO mlflow.tracking.fluent: Experiment with name 'Classification_Model_Comparison' does not exist. Creating a new experiment.\n",
      "d:\\archit\\mlops\\Fraud-Detection-System--End-to-end-ml-project-\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2026/02/24 16:03:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/24 16:04:01 WARNING mlflow.sklearn: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. The recommended safe alternative is the 'skops' format. For more information, see: https://scikit-learn.org/stable/model_persistence.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression logged to MLflow\n",
      "üèÉ View run LogisticRegression at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1/runs/dd6043655a0e4e0e8c3ac5a0c478eef8\n",
      "üß™ View experiment at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/24 16:04:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/24 16:04:28 WARNING mlflow.sklearn: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. The recommended safe alternative is the 'skops' format. For more information, see: https://scikit-learn.org/stable/model_persistence.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest logged to MLflow\n",
      "üèÉ View run RandomForest at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1/runs/f2a590f4b30041448725c67f55d5f092\n",
      "üß™ View experiment at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/24 16:04:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/24 16:04:52 WARNING mlflow.sklearn: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. The recommended safe alternative is the 'skops' format. For more information, see: https://scikit-learn.org/stable/model_persistence.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree logged to MLflow\n",
      "üèÉ View run DecisionTree at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1/runs/9204c47e401f402399226bbd6848f86b\n",
      "üß™ View experiment at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/24 16:05:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/02/24 16:05:16 WARNING mlflow.sklearn: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. The recommended safe alternative is the 'skops' format. For more information, see: https://scikit-learn.org/stable/model_persistence.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM logged to MLflow\n",
      "üèÉ View run SVM at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1/runs/4529ac8643274a73a982fa864dd62fa3\n",
      "üß™ View experiment at: https://dagshub.com/ArchitSaki/Fraud-Detection-System--End-to-end-ml-project-.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "mlflow.set_experiment(\"Classification_Model_Comparison\")\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"{model_name} logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c91d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
